{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'C:/Users/29578/Downloads/penn state/2020 Spring/PHS 597 Deep Learning/data/mnist.npz'\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "fig, axs = plt.subplots(2,2)\n",
    "for ii in np.arange(0,2):\n",
    "    for jj in np.arange(0,2):\n",
    "        axs[ii,jj].imshow(train_images[ii*2+jj,:,:])\n",
    "        axs[ii,jj].title.set_text(train_labels[ii*2+jj]) #show title: the label\n",
    "##print(range(0,2))\n",
    "##plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "?models.Sequential\n",
    "?layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\29578\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "#512: self-determined as dimension of output vector. 28*28 pixels. \n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "#10: self-determined dimension of output.10 categories of labels: 0,1,...9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 512) dtype=float32>,\n",
       " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(512, 10) dtype=float32>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reshape and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels_cat = to_categorical(train_labels)\n",
    "test_labels_cat = to_categorical(test_labels)\n",
    "#?to_categorical:convert a class vector to binary class matrix\n",
    "#test agreement of train and test: 10 rows of categories, 2 columns for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 58s 958us/sample - loss: 0.2547 - acc: 0.9266\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 25s 413us/sample - loss: 0.1038 - acc: 0.9689 - loss: 0.1046 \n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.0685 - acc: 0.9802\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 15s 242us/sample - loss: 0.0504 - acc: 0.9847 - loss: - ETA: 5s -  - ETA: 1\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.0377 - acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e880283948>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels_cat, epochs=5, batch_size=128)\n",
    "#x:input data. y: target data\n",
    "#batch size: self-determined. # of smples per gradient update. # of figures used to train NN\n",
    "#epoch: integer. # of epoches to train the model. an epoch is an iteration over the entire data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test model (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 719us/sample - loss: 0.0682 - acc: 0.98050s - loss: 0.0928 - - E\n",
      "0.9805\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels_cat)\n",
    "print(test_acc)\n",
    "#test_acc: accuracy of prediction compared with the truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five Machine Learning Models were implemented to MNIST dataset. The accuracy of prediction for the five models was compared with NN example (accuracy=0.9805).\n",
    "    Model 1: Support Vector Machine (SVM). Accuracy=0.9786\n",
    "    Model 2: Random Forest. Accuracy=0.9715\n",
    "    Model 3: K-Nearest Neighbors. Accuracy=0.9688\n",
    "    Model 4: multinomial logistic with L2 penalty. Accuracy=0.8978 \n",
    "    Model 5: Neural Network. (This multi-layer Perceptron classifier optimizes the log-loss function using LBFGS). Accuracy=0.981\n",
    "   \n",
    "An example of cross-validation and grid search was offered at the end to train hyperparameters in the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "train_images1 = train_images[1:5001,]\n",
    "train_labels1 = train_labels[1:5001,]\n",
    "test_images1 = test_images[1:1001,]\n",
    "test_labels1 = test_labels[1:1001,]\n",
    "print(train_images1.shape)\n",
    "print(train_labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.925 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kernel Function Selection. use 5000 images for training and 100 for testing\n",
    "# 1. linear model. SVC(kernel='linear') accuracy: 0.889 \n",
    "# 2. nonlinear model. SVC(kernel='poly',gamma=\"scale\") accuracy: 0.92\n",
    "# 2.1 nonlinear model. SVC(kernel='poly',gamma=\"scale\",C=10) accuracy: 0.925\n",
    "# 3. nonlinear model. SVC(C=15, gamma=0.001, kernel=\"rbf\") accuracy: 0.917\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "model_linear = SVC(kernel='poly',gamma=\"scale\",C=10)\n",
    "model_linear.fit(train_images1, train_labels1)\n",
    "test_pred = model_linear.predict(test_images1)\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=test_labels1, y_pred=test_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9786 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_linear = SVC(kernel='poly',gamma=\"scale\",C=10)\n",
    "model_linear.fit(train_images, train_labels)\n",
    "# accuracy\n",
    "test_pred = model_linear.predict(test_images)\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=test_labels, y_pred=test_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.921\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "rf = RandomForestClassifier(n_estimators=150,max_depth=10) \n",
    "#n_estimators and max_depth controlled by cross-validation\n",
    "#n_estimators: number of trees. \n",
    "#max_depth : The maximum depth of the tree. log_2(28*28)=9.6\n",
    "print(\"Train model\")\n",
    "rf.fit(train_images1, train_labels1)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_rf = rf.predict(test_images1)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels1, test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning hyperparameters\n",
    "#model 1. rf = RandomForestClassifier(n_estimators=150,max_depth=10). Accuracy=0.948\n",
    "#model 2. rf = RandomForestClassifier(n_estimators=100). Accuracy=0.9699\n",
    "#model 3. rf = RandomForestClassifier(n_estimators=150). Accuracy=0.9708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.9715\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "rf = RandomForestClassifier(n_estimators=250)\n",
    "print(\"Train model\")\n",
    "rf.fit(train_images, train_labels)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_rf = rf.predict(test_images)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels, test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.91\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "print(\"Train model\")\n",
    "knn.fit(train_images1, train_labels1)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_knn = knn.predict(test_images1)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels1, test_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.9688\n"
     ]
    }
   ],
   "source": [
    "print(\"Train model\")\n",
    "knn.fit(train_images, train_labels)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_knn = knn.predict(test_images)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels, test_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: multinomial logistic with L2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.875\n"
     ]
    }
   ],
   "source": [
    "train_samples1 = 5000\n",
    "clf = LogisticRegression(C=50. / train_samples1, penalty='l2', solver='saga', tol=0.1,multi_class=\"auto\")#multi_class=10\n",
    "print(\"Train model\")\n",
    "clf.fit(train_images1, train_labels1)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_clf = clf.predict(test_images1)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels1, test_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.8978\n"
     ]
    }
   ],
   "source": [
    "train_samples = 60000\n",
    "clf = LogisticRegression(C=50. / train_samples, penalty='l2', solver='saga', tol=0.1,multi_class=\"auto\")\n",
    "print(\"Train model\")\n",
    "clf.fit(train_images, train_labels)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_clf = clf.predict(test_images)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels, test_pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MLPClassifier \n",
    "#Multi-layer Perceptron classifier.optimizes the log-loss function using LBFGS or stochastic gradient descent.\n",
    "#default activation function for hidden layer is Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.924\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(1000,),  random_state=1 ) \n",
    "print(\"Train model\")\n",
    "clf.fit(train_images1, train_labels1)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_clf = clf.predict(test_images1)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels1, test_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Compute predictions\n",
      "Accuracy:  0.981\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(1000,),  random_state=1 ) \n",
    "print(\"Train model\")\n",
    "clf.fit(train_images, train_labels)\n",
    "print(\"Compute predictions\")\n",
    "test_pred_clf = clf.predict(test_images)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(test_labels, test_pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Training Hyperparameter by Cross-validation and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 9 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "#20-fold cross validation\n",
    "# creating a KFold object with 20 splits \n",
    "folds = KFold(n_splits = 20, shuffle = True, random_state = 10)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [ {'n_estimators': [100, 150,250],\n",
    "                     'max_depth': [8,9,10]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model = RandomForestClassifier() \n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(train_images1, train_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.551600</td>\n",
       "      <td>0.271128</td>\n",
       "      <td>0.045159</td>\n",
       "      <td>0.020912</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 70}</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>12</td>\n",
       "      <td>0.97575</td>\n",
       "      <td>0.97800</td>\n",
       "      <td>0.97725</td>\n",
       "      <td>0.97925</td>\n",
       "      <td>0.97475</td>\n",
       "      <td>0.97700</td>\n",
       "      <td>0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.157482</td>\n",
       "      <td>0.138588</td>\n",
       "      <td>0.060863</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>11</td>\n",
       "      <td>0.97850</td>\n",
       "      <td>0.97725</td>\n",
       "      <td>0.97925</td>\n",
       "      <td>0.97675</td>\n",
       "      <td>0.98050</td>\n",
       "      <td>0.97845</td>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.695446</td>\n",
       "      <td>0.183625</td>\n",
       "      <td>0.064410</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 150}</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97900</td>\n",
       "      <td>0.97750</td>\n",
       "      <td>0.98050</td>\n",
       "      <td>0.97975</td>\n",
       "      <td>0.97975</td>\n",
       "      <td>0.97930</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.912715</td>\n",
       "      <td>0.283135</td>\n",
       "      <td>0.106038</td>\n",
       "      <td>0.030729</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 250}</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.010613</td>\n",
       "      <td>8</td>\n",
       "      <td>0.97950</td>\n",
       "      <td>0.97950</td>\n",
       "      <td>0.98150</td>\n",
       "      <td>0.97900</td>\n",
       "      <td>0.97975</td>\n",
       "      <td>0.97985</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.595959</td>\n",
       "      <td>0.179214</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 70}</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>9</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.98850</td>\n",
       "      <td>0.98825</td>\n",
       "      <td>0.99025</td>\n",
       "      <td>0.99025</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>0.000872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.327038</td>\n",
       "      <td>0.073123</td>\n",
       "      <td>0.048860</td>\n",
       "      <td>0.021724</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>6</td>\n",
       "      <td>0.98975</td>\n",
       "      <td>0.99125</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>0.99225</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>0.99105</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.341123</td>\n",
       "      <td>0.263716</td>\n",
       "      <td>0.124854</td>\n",
       "      <td>0.057110</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 150}</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>0.008935</td>\n",
       "      <td>4</td>\n",
       "      <td>0.98950</td>\n",
       "      <td>0.99250</td>\n",
       "      <td>0.99050</td>\n",
       "      <td>0.99050</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.99060</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.399314</td>\n",
       "      <td>0.229177</td>\n",
       "      <td>0.115128</td>\n",
       "      <td>0.020718</td>\n",
       "      <td>9</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 250}</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>0.99150</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>0.99150</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.653467</td>\n",
       "      <td>0.191421</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 70}</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99475</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>0.99575</td>\n",
       "      <td>0.99625</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>0.99555</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.385401</td>\n",
       "      <td>0.178396</td>\n",
       "      <td>0.045759</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>0.99575</td>\n",
       "      <td>0.99575</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.99595</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.660859</td>\n",
       "      <td>0.195943</td>\n",
       "      <td>0.076393</td>\n",
       "      <td>0.025477</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 150}</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9348</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99575</td>\n",
       "      <td>0.99725</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.99575</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.99640</td>\n",
       "      <td>0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.920652</td>\n",
       "      <td>1.112184</td>\n",
       "      <td>0.147262</td>\n",
       "      <td>0.084185</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 250}</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99525</td>\n",
       "      <td>0.99725</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.99645</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.551600      0.271128         0.045159        0.020912   \n",
       "1        2.157482      0.138588         0.060863        0.019533   \n",
       "2        3.695446      0.183625         0.064410        0.017864   \n",
       "3        5.912715      0.283135         0.106038        0.030729   \n",
       "4        1.595959      0.179214         0.032080        0.011230   \n",
       "5        2.327038      0.073123         0.048860        0.021724   \n",
       "6        3.341123      0.263716         0.124854        0.057110   \n",
       "7        5.399314      0.229177         0.115128        0.020718   \n",
       "8        1.653467      0.191421         0.031908        0.011442   \n",
       "9        2.385401      0.178396         0.045759        0.010560   \n",
       "10       3.660859      0.195943         0.076393        0.025477   \n",
       "11       6.920652      1.112184         0.147262        0.084185   \n",
       "\n",
       "   param_max_depth param_n_estimators                                  params  \\\n",
       "0                8                 70    {'max_depth': 8, 'n_estimators': 70}   \n",
       "1                8                100   {'max_depth': 8, 'n_estimators': 100}   \n",
       "2                8                150   {'max_depth': 8, 'n_estimators': 150}   \n",
       "3                8                250   {'max_depth': 8, 'n_estimators': 250}   \n",
       "4                9                 70    {'max_depth': 9, 'n_estimators': 70}   \n",
       "5                9                100   {'max_depth': 9, 'n_estimators': 100}   \n",
       "6                9                150   {'max_depth': 9, 'n_estimators': 150}   \n",
       "7                9                250   {'max_depth': 9, 'n_estimators': 250}   \n",
       "8               10                 70   {'max_depth': 10, 'n_estimators': 70}   \n",
       "9               10                100  {'max_depth': 10, 'n_estimators': 100}   \n",
       "10              10                150  {'max_depth': 10, 'n_estimators': 150}   \n",
       "11              10                250  {'max_depth': 10, 'n_estimators': 250}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  ...  \\\n",
       "0               0.924              0.932              0.903  ...   \n",
       "1               0.928              0.934              0.915  ...   \n",
       "2               0.926              0.934              0.914  ...   \n",
       "3               0.934              0.938              0.916  ...   \n",
       "4               0.930              0.927              0.914  ...   \n",
       "5               0.933              0.942              0.918  ...   \n",
       "6               0.930              0.944              0.930  ...   \n",
       "7               0.929              0.943              0.925  ...   \n",
       "8               0.922              0.939              0.921  ...   \n",
       "9               0.936              0.944              0.924  ...   \n",
       "10              0.942              0.950              0.931  ...   \n",
       "11              0.939              0.946              0.933  ...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0            0.9136        0.012142               12             0.97575   \n",
       "1            0.9198        0.009968               11             0.97850   \n",
       "2            0.9218        0.007808               10             0.97900   \n",
       "3            0.9234        0.010613                8             0.97950   \n",
       "4            0.9224        0.006020                9             0.98875   \n",
       "5            0.9272        0.010796                6             0.98975   \n",
       "6            0.9294        0.008935                4             0.98950   \n",
       "7            0.9280        0.008149                5             0.99100   \n",
       "8            0.9256        0.006859                7             0.99475   \n",
       "9            0.9298        0.008727                3             0.99500   \n",
       "10           0.9348        0.009745                2             0.99575   \n",
       "11           0.9352        0.006554                1             0.99525   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0              0.97800             0.97725             0.97925   \n",
       "1              0.97725             0.97925             0.97675   \n",
       "2              0.97750             0.98050             0.97975   \n",
       "3              0.97950             0.98150             0.97900   \n",
       "4              0.98850             0.98825             0.99025   \n",
       "5              0.99125             0.99100             0.99225   \n",
       "6              0.99250             0.99050             0.99050   \n",
       "7              0.99150             0.99100             0.99150   \n",
       "8              0.99550             0.99575             0.99625   \n",
       "9              0.99575             0.99575             0.99650   \n",
       "10             0.99725             0.99675             0.99575   \n",
       "11             0.99725             0.99650             0.99675   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.97475           0.97700         0.001597  \n",
       "1              0.98050           0.97845         0.001355  \n",
       "2              0.97975           0.97930         0.001017  \n",
       "3              0.97975           0.97985         0.000860  \n",
       "4              0.99025           0.98920         0.000872  \n",
       "5              0.99100           0.99105         0.000797  \n",
       "6              0.99000           0.99060         0.001020  \n",
       "7              0.99100           0.99120         0.000245  \n",
       "8              0.99550           0.99555         0.000485  \n",
       "9              0.99675           0.99595         0.000620  \n",
       "10             0.99650           0.99640         0.000583  \n",
       "11             0.99650           0.99645         0.000660  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results\n",
    "#choose the combination n_estimators=150,max_depth=10 with rank_test_score=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.97700\n",
      "1     0.97845\n",
      "2     0.97930\n",
      "3     0.97985\n",
      "4     0.98920\n",
      "5     0.99105\n",
      "6     0.99060\n",
      "7     0.99120\n",
      "8     0.99555\n",
      "9     0.99595\n",
      "10    0.99640\n",
      "11    0.99645\n",
      "Name: mean_train_score, dtype: float64\n",
      "0     0.9136\n",
      "1     0.9198\n",
      "2     0.9218\n",
      "3     0.9234\n",
      "4     0.9224\n",
      "5     0.9272\n",
      "6     0.9294\n",
      "7     0.9280\n",
      "8     0.9256\n",
      "9     0.9298\n",
      "10    0.9348\n",
      "11    0.9352\n",
      "Name: mean_test_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cv_results[\"mean_train_score\"]) \n",
    "print(cv_results[\"mean_test_score\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e8b5716e88>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_results['param_n_estimators'] = cv_results['param_n_estimators'].astype('int')\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# subplot 1/4\n",
    "plt.subplot(141)\n",
    "n_01 = cv_results[cv_results['param_n_estimators']==70]\n",
    "\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_test_score\"])\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_train_score\"])\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"n_estimators=70\")\n",
    "#plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "\n",
    "# subplot 2/4\n",
    "plt.subplot(142)\n",
    "n_01 = cv_results[cv_results['param_n_estimators']==100]\n",
    "\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_test_score\"])\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_train_score\"])\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"n_estimators=70\")\n",
    "#plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "\n",
    "# subplot 3/4\n",
    "plt.subplot(142)\n",
    "n_01 = cv_results[cv_results['param_n_estimators']==150]\n",
    "\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_test_score\"])\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_train_score\"])\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"n_estimators=70\")\n",
    "#plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "\n",
    "# subplot 4/4\n",
    "plt.subplot(142)\n",
    "n_01 = cv_results[cv_results['param_n_estimators']==200]\n",
    "\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_test_score\"])\n",
    "plt.plot(n_01[\"param_n_estimators\"], n_01[\"mean_train_score\"])\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"n_estimators=70\")\n",
    "#plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
